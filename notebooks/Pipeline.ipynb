{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "Joel Piper 2016-09-17 20:10:01 \n",
      "\n",
      "CPython 2.7.12\n",
      "IPython 4.2.0\n",
      "\n",
      "numpy 1.11.1\n",
      "pandas 0.18.1\n",
      "nltk 3.2.1\n",
      "sklearn 0.17.1\n",
      "gensim 0.13.2\n",
      "Git hash: 2e718645ec0e62dd529a4b2784c93c884eff7694\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a \"Joel Piper\" -d -t -v -p numpy,pandas,nltk,sklearn,gensim -g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and Lemmatize the Word List in Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "con = psycopg2.connect(dbname='bills_db', user='joeljoel')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Return first 1000 us bills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qb/nxfghts14xv2gh9svxdkp3d40000gn/T/ipykernel_60924/4021389032.py:8: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  us_bills = pd.read_sql_query(sql_query, con)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# query:\n",
    "sql_query = \"\"\"\n",
    "SELECT *\n",
    "FROM us_bills\n",
    "LIMIT 1000;\n",
    "\"\"\"\n",
    "us_bills = pd.read_sql_query(sql_query, con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now get the subjects for those 1000 bills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qb/nxfghts14xv2gh9svxdkp3d40000gn/T/ipykernel_60924/1387348034.py:9: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  subjects = pd.read_sql_query(revised, con)\n"
     ]
    }
   ],
   "source": [
    "# query:\n",
    "sql_query = \"\"\"\n",
    "SELECT *\n",
    "FROM bill_subject\n",
    "WHERE bill_num IN (' {0} ');\n",
    "\"\"\"\n",
    "\n",
    "revised = sql_query.format(\"','\".join(us_bills['bill_num']))\n",
    "subjects = pd.read_sql_query(revised, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "bill_subset = us_bills.loc[0:1000,['bill_name','bill_text']]\n",
    "bill_tuples = [tuple(x) for x in bill_subset.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk import word_tokenize          \n",
    "#from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#######\n",
    "# Use a lemmatizer rather than just a stemmer\n",
    "#stemmer = PorterStemmer()\n",
    "#def stem_tokens(tokens, stemmer):\n",
    "#    stemmed = []\n",
    "#    for item in tokens:\n",
    "#        stemmed.append(stemmer.stem(item))\n",
    "#    return stemmed\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_tokens(tokens, lemma):\n",
    "    lemmatized = []\n",
    "    for item in tokens:\n",
    "        lemmatized.append(lemma.lemmatize(item))\n",
    "    return lemmatized\n",
    "\n",
    "def tokenize(text):\n",
    "    text = \"\".join([ch for ch in text if ch not in string.punctuation])\n",
    "    text = \"\".join([ch for ch in text if ch not in string.digits])\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmas = lemmatize_tokens(tokens, wordnet_lemmatizer)\n",
    "    return lemmas\n",
    "\n",
    "def my_preproc_text(bill_tuple):\n",
    "    text = bill_tuple[1].lower()\n",
    "    revised = \" \".join([t for t in text.split() if len(t) > 3])\n",
    "    return revised\n",
    "\n",
    "def my_preproc_title(bill_tuple):\n",
    "    title = bill_tuple[0].lower()\n",
    "    revised = \" \".join([t for t in title.split() if len(t) > 3])\n",
    "    return revised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from textblob import TextBlob\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "tf_text = CountVectorizer(stop_words='english', token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=tokenize,\n",
    "                          preprocessor=my_preproc_text, ngram_range=(1,2), min_df=10, max_df=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tf_title = CountVectorizer(stop_words='english', token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=tokenize,\n",
    "                           preprocessor=my_preproc_title, ngram_range=(1,3), min_df=10, max_df=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the TF/IDF and LDA Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_text = TfidfVectorizer(stop_words='english', token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=tokenize,\n",
    "                             preprocessor=my_preproc_text, ngram_range=(1,2), min_df=10, max_df=0.4)\n",
    "tfidf_title = TfidfVectorizer(stop_words='english', token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=tokenize,\n",
    "                             preprocessor=my_preproc_title, ngram_range=(1,3), min_df=10, max_df=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda_text = LatentDirichletAllocation(n_components=100, max_iter=5, learning_method='online', learning_offset=50., \n",
    "                                     random_state=0)\n",
    "lda_title = LatentDirichletAllocation(n_components=10, max_iter=5, learning_method='online', learning_offset=50., \n",
    "                                     random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()\n",
    "n_top_words = 20\n",
    "tf_feature_names = tf_title.get_feature_names_out()\n",
    "print_top_words(lda_title, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Create the logistic regression model using gridcv from scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "health_bills = subjects[subjects['subject'] == 'Health']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_bills['health'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "us_bills[[us_bills['bill_num'].isin(health_bills['bill_num']),'health']] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "lda_text_model = Pipeline(steps=[('tf_text', tf_text), ('lda_text', lda_text)])\n",
    "lda_title_model = Pipeline(steps=[('tf_title', tf_title), ('lda_title', lda_title)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "combined_features = FeatureUnion([(\"tfidf_text\", tfidf_text), (\"lda_text_model\", lda_text_model), \n",
    "                                  (\"tfidf_title\", tfidf_title), (\"lda_title_model\", lda_title_model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic = LogisticRegression(C=1e9, penalty='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('features', combined_features), ('logistic', logistic)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "param_grid = dict(features__lda_text_model__lda_text__n_components=[100],\n",
    "                  features__lda_title_model__lda_title__n_components=[10],\n",
    "                  features__tfidf_text__max_features=[None, 100],\n",
    "                  features__tfidf_title__max_features=[None],\n",
    "                  logistic__C=[0.1, 1, 10, 1e9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, scoring='roc_auc', verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV 1/5; 1/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joeljoel/mambaforge/envs/bill_taxonomy/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 1/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=0.1;, score=nan total time=  18.4s\n",
      "[CV 2/5; 1/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=0.1\n",
      "[CV 2/5; 1/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=0.1;, score=nan total time=  17.1s\n",
      "[CV 3/5; 1/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=0.1\n",
      "[CV 3/5; 1/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=0.1;, score=nan total time=  14.4s\n",
      "[CV 4/5; 1/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=0.1\n",
      "[CV 4/5; 1/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=0.1;, score=nan total time=  13.3s\n",
      "[CV 5/5; 1/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=0.1\n",
      "[CV 5/5; 1/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=0.1;, score=nan total time=  14.8s\n",
      "[CV 1/5; 2/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=1\n",
      "[CV 1/5; 2/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=1;, score=nan total time=  17.7s\n",
      "[CV 2/5; 2/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=1\n",
      "[CV 2/5; 2/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=1;, score=nan total time=  17.2s\n",
      "[CV 3/5; 2/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=1\n",
      "[CV 3/5; 2/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=1;, score=nan total time=  15.7s\n",
      "[CV 4/5; 2/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=1\n",
      "[CV 4/5; 2/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=1;, score=nan total time=  13.8s\n",
      "[CV 5/5; 2/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=1\n",
      "[CV 5/5; 2/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=1;, score=nan total time=  16.3s\n",
      "[CV 1/5; 3/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=10\n",
      "[CV 1/5; 3/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=10;, score=nan total time=  18.6s\n",
      "[CV 2/5; 3/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=10\n",
      "[CV 2/5; 3/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=10;, score=nan total time=  17.7s\n",
      "[CV 3/5; 3/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=10\n",
      "[CV 3/5; 3/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=10;, score=nan total time=  16.2s\n",
      "[CV 4/5; 3/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=10\n",
      "[CV 4/5; 3/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=10;, score=nan total time=  13.3s\n",
      "[CV 5/5; 3/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=10\n",
      "[CV 5/5; 3/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=10;, score=nan total time=  15.3s\n",
      "[CV 1/5; 4/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=1000000000.0\n",
      "[CV 1/5; 4/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=1000000000.0;, score=nan total time=  18.4s\n",
      "[CV 2/5; 4/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=1000000000.0\n",
      "[CV 2/5; 4/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=1000000000.0;, score=nan total time=  17.7s\n",
      "[CV 3/5; 4/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=1000000000.0\n",
      "[CV 3/5; 4/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=1000000000.0;, score=nan total time=  14.8s\n",
      "[CV 4/5; 4/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=1000000000.0\n",
      "[CV 4/5; 4/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=1000000000.0;, score=nan total time=  14.3s\n",
      "[CV 5/5; 4/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=1000000000.0\n",
      "[CV 5/5; 4/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=None, features__tfidf_title__max_features=None, logistic__C=1000000000.0;, score=nan total time=  15.4s\n",
      "[CV 1/5; 5/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=0.1\n",
      "[CV 1/5; 5/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=0.1;, score=nan total time=  18.6s\n",
      "[CV 2/5; 5/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=0.1\n",
      "[CV 2/5; 5/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=0.1;, score=nan total time=  17.3s\n",
      "[CV 3/5; 5/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=0.1\n",
      "[CV 3/5; 5/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=0.1;, score=nan total time=  14.5s\n",
      "[CV 4/5; 5/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=0.1\n",
      "[CV 4/5; 5/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=0.1;, score=nan total time=  13.9s\n",
      "[CV 5/5; 5/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=0.1\n",
      "[CV 5/5; 5/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=0.1;, score=nan total time=  16.6s\n",
      "[CV 1/5; 6/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=1\n",
      "[CV 1/5; 6/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=1;, score=nan total time=  19.0s\n",
      "[CV 2/5; 6/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=1\n",
      "[CV 2/5; 6/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=1;, score=nan total time=  17.9s\n",
      "[CV 3/5; 6/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=1\n",
      "[CV 3/5; 6/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=1;, score=nan total time=  15.4s\n",
      "[CV 4/5; 6/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=1\n",
      "[CV 4/5; 6/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=1;, score=nan total time=  13.9s\n",
      "[CV 5/5; 6/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=1\n",
      "[CV 5/5; 6/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=1;, score=nan total time=  17.2s\n",
      "[CV 1/5; 7/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=10\n",
      "[CV 1/5; 7/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=10;, score=nan total time=  20.5s\n",
      "[CV 2/5; 7/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=10\n",
      "[CV 2/5; 7/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=10;, score=nan total time=  17.8s\n",
      "[CV 3/5; 7/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=10\n",
      "[CV 3/5; 7/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=10;, score=nan total time=  16.2s\n",
      "[CV 4/5; 7/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=10\n",
      "[CV 4/5; 7/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=10;, score=nan total time=  15.2s\n",
      "[CV 5/5; 7/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=10\n",
      "[CV 5/5; 7/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=10;, score=nan total time=  15.4s\n",
      "[CV 1/5; 8/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=1000000000.0\n",
      "[CV 1/5; 8/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=1000000000.0;, score=nan total time=  18.8s\n",
      "[CV 2/5; 8/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=1000000000.0\n",
      "[CV 2/5; 8/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=1000000000.0;, score=nan total time=  17.6s\n",
      "[CV 3/5; 8/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=1000000000.0\n",
      "[CV 3/5; 8/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=1000000000.0;, score=nan total time=  15.0s\n",
      "[CV 4/5; 8/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=1000000000.0\n",
      "[CV 4/5; 8/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=1000000000.0;, score=nan total time=  14.0s\n",
      "[CV 5/5; 8/8] START features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=1000000000.0\n",
      "[CV 5/5; 8/8] END features__lda_text_model__lda_text__n_components=100, features__lda_title_model__lda_title__n_components=10, features__tfidf_text__max_features=100, features__tfidf_title__max_features=None, logistic__C=1000000000.0;, score=nan total time=  15.3s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 40 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n40 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/joeljoel/mambaforge/envs/bill_taxonomy/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/joeljoel/mambaforge/envs/bill_taxonomy/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/joeljoel/mambaforge/envs/bill_taxonomy/lib/python3.11/site-packages/sklearn/pipeline.py\", line 420, in fit\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n  File \"/Users/joeljoel/mambaforge/envs/bill_taxonomy/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/joeljoel/mambaforge/envs/bill_taxonomy/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n    solver = _check_solver(self.solver, self.penalty, self.dual)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/joeljoel/mambaforge/envs/bill_taxonomy/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n    raise ValueError(\nValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(bill_tuples, us_bills[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhealth\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/mambaforge/envs/bill_taxonomy/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/envs/bill_taxonomy/lib/python3.11/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/mambaforge/envs/bill_taxonomy/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m~/mambaforge/envs/bill_taxonomy/lib/python3.11/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    870\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    873\u001b[0m     )\n\u001b[0;32m--> 875\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_score)\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/mambaforge/envs/bill_taxonomy/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    408\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    413\u001b[0m     )\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 40 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n40 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/joeljoel/mambaforge/envs/bill_taxonomy/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/joeljoel/mambaforge/envs/bill_taxonomy/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/joeljoel/mambaforge/envs/bill_taxonomy/lib/python3.11/site-packages/sklearn/pipeline.py\", line 420, in fit\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n  File \"/Users/joeljoel/mambaforge/envs/bill_taxonomy/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/joeljoel/mambaforge/envs/bill_taxonomy/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n    solver = _check_solver(self.solver, self.penalty, self.dual)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/joeljoel/mambaforge/envs/bill_taxonomy/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n    raise ValueError(\nValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(bill_tuples, us_bills['health'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For visualization and reporting interest only, leave out 10% to plot a ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "fig_dir = '/Users/Joel/Desktop/Insight/data/'\n",
    "def make_roc_curve(pipeline, X, y, train_frac, subject, fig_dir):\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, y, train_size=train_frac, random_state=1, stratify=y)\n",
    "    grid_search = GridSearchCV(pipeline, {}, scoring='roc_auc', verbose=10)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    y_pred_class = grid_search.predict(X_test)\n",
    "    y_pred_prob = grid_search.predict_proba(X_test)[:, 1]\n",
    "    print(metrics.accuracy_score(y_test, y_pred_class))\n",
    "    print(metrics.confusion_matrix(y_test, y_pred_class))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_prob)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    # method I: plt\n",
    "\n",
    "    plt.title(subject + '\\nReceiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "    plt.savefig(fig_dir+'/roc_curve_'+subject.lower()+'.png')\n",
    "    results_save = (grid_search, X_test, y_test)\n",
    "    pickle.dump(results_save, open(fig_dir+'/plot_info_nb.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "grid_search, X_test, y_test = pickle.load(open(fig_dir+'/plot_info.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "make_roc_curve(pipe_nb, bill_tuples, us_bills['health'], 0.9, 'Health', '/Users/Joel/Desktop/Insight/data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "pipe_svc = Pipeline(steps=[('features', combined_features), ('svc', svc)])\n",
    "param_grid_svc = dict(features__lda_text_model__lda_text__n_topics=[100],\n",
    "                  features__lda_title_model__lda_title__n_topics=[10],\n",
    "                  features__tfidf_text__max_features=[None],\n",
    "                  features__tfidf_title__max_features=[None],\n",
    "                  svc__C=[1])\n",
    "grid_search_svc = GridSearchCV(pipe_svc, param_grid=param_grid_svc, scoring='roc_auc', verbose=10)\n",
    "grid_search_svc.fit(bill_tuples, us_bills['health'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "grid_search_svc.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "pipe_nb = Pipeline(steps=[('features', combined_features), ('nb', nb)])\n",
    "param_grid_nb = dict(features__lda_text_model__lda_text__n_topics=[100],\n",
    "                  features__lda_title_model__lda_title__n_topics=[10],\n",
    "                  features__tfidf_text__max_features=[None],\n",
    "                  features__tfidf_title__max_features=[None],\n",
    "                  nb__alpha=[1])\n",
    "grid_search_nb = GridSearchCV(pipe_nb, param_grid=param_grid_nb, scoring='roc_auc', verbose=10)\n",
    "grid_search_nb.fit(bill_tuples, us_bills['health'])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
